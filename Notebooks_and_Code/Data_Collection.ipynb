{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "## Table of Contents:\n",
    "1. [List of Movies](#names)\n",
    "2. [List of Reviews](#reviews)\n",
    "3. [Reviews for a Genre](#genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Movies <a id='names'></a>\n",
    "\n",
    "First, we'll need to grab our list of movie names from IMDB. We use the \"Horror\" genre because I think the words mentioned in these reviews should prove useful features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titles(movies_container):\n",
    "    \"\"\"Returns list of movie titles from IMDB search results.\"\"\"\n",
    "    return [h3.find('a').get_text() for h3 in movies_container.findAll('h3')]\n",
    "\n",
    "def years(movies_container):\n",
    "    \"\"\"Returns list of movie release years from IMDB search results.\"\"\"\n",
    "    return [h3.find('span', class_='lister-item-year text-muted unbold').get_text().strip('(I) ') for h3 in movies_container.findAll('h3')]\n",
    "\n",
    "def collect_imdb_data(imdb_seach_url, total_results):\n",
    "    \"\"\"Returns list of titles and year of release for given number of results.\n",
    "    Expect this function to take (total_results/50)/2 seconds.\n",
    "    Total results should be less than 10,000.\"\"\"\n",
    "    #initialize all lists\n",
    "    all_titles = []\n",
    "    all_years = []\n",
    "    #create soup for first page\n",
    "    html_page = requests.get(imdb_seach_url)\n",
    "    html_tree = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    #create containers for first page\n",
    "    movies_container = html_tree.find('div', class_=\"lister-list\")\n",
    "    imdb_movie_list = movies_container.findAll('div', class_=\"lister-item-content\")\n",
    "    #collect first page data\n",
    "    for title in titles(movies_container):\n",
    "        all_titles.append(title)\n",
    "    #check if total_results is greater than 10,000 since the IMDB URL changes after that many results\n",
    "    if total_results > 10_000:\n",
    "        print(\"The amount of results is too large, this function can only support up to 10,000. Collecting data for top 10,000 results only.\")\n",
    "        total_results = 10_001\n",
    "    #iterate through the rest of the results to collect data\n",
    "    for i in range(51,total_results+50,50):\n",
    "        #create soup for current page\n",
    "        url = imdb_seach_url+f\"&start={i}&ref_=adv_nxt\"\n",
    "        html_page = requests.get(url)\n",
    "        html_tree = BeautifulSoup(html_page.content, 'html.parser')\n",
    "        #create containers for current page\n",
    "        movies_container = html_tree.find('div', class_=\"lister-list\")\n",
    "        imdb_movie_list = movies_container.findAll('div', class_=\"lister-item-content\")\n",
    "        #collect current page data\n",
    "        for title in titles(movies_container):\n",
    "            all_titles.append(title)\n",
    "        for year in years(movies_container):\n",
    "            all_years.append(year)\n",
    "        #buffer for half a second so as to not DDOS IMDB\n",
    "        time.sleep(0.5)\n",
    "    #combine and return page data\n",
    "    return list(zip(all_titles, all_years))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Reviews <a id='reviews'></a>\n",
    "\n",
    "Now that we have a list of 1,000 movies and their respective release year, we can use this information to grab all of the reviews for these horror movies from Rotten Tomatoes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts(review_list):\n",
    "    \"\"\"Returns list of reviews from Rotten Tomato search results.\"\"\"\n",
    "    return [review.find('div', class_='the_review').get_text() for review in review_list.findAll('div', class_='row review_table_row')]\n",
    "\n",
    "def scores(review_list):\n",
    "    \"\"\"Returns list of scores from Rotten Tomato search results.\"\"\"\n",
    "    return [review.find('div', class_='col-xs-16 review_container').findChildren('div')[0].get('class')[-1] for review in review_list.findAll('div', class_='row review_table_row')]\n",
    "\n",
    "def collect_rt_reviews(name, year):\n",
    "    \"\"\"Returns list of text and scores of reviews for given RT search results.\"\"\"\n",
    "    rt_search_url = f\"https://www.rottentomatoes.com/m/{name}_{year}/reviews?type=top_critics\"\n",
    "    #initialize all lists\n",
    "    all_text = []\n",
    "    all_scores = []\n",
    "    #create soup for first page\n",
    "    html_page = requests.get(rt_search_url)\n",
    "    html_tree = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    reviews_container = html_tree.find('div', class_=\"content\")\n",
    "    #some RT urls do not contain the date, this if checks for that case\n",
    "    if reviews_container is None:\n",
    "#         print(f\"{name} not found on RT, trying without year.\") #debug\n",
    "        rt_search_url = f\"https://www.rottentomatoes.com/m/{name}/reviews?type=top_critics\"\n",
    "        html_page = requests.get(rt_search_url)\n",
    "        html_tree = BeautifulSoup(html_page.content, 'html.parser')\n",
    "        reviews_container = html_tree.find('div', class_=\"content\")\n",
    "    #if the page is still not found, return empty lists\n",
    "    if reviews_container is None:\n",
    "#         print(f\"{name} not found on RT, returning empty list.\") #debug\n",
    "        return list(zip(all_text, all_scores))\n",
    "    review_list = reviews_container.find('div', class_='review_table')\n",
    "    for text in texts(review_list):\n",
    "        all_text.append(text)\n",
    "    for score in scores(review_list):\n",
    "        all_scores.append(score)\n",
    "    #look for page information\n",
    "    page_info = reviews_container.findAll('span', class_='pageInfo')\n",
    "    #if there is more than one page\n",
    "    if page_info:\n",
    "        #grab number of pages\n",
    "        num_pages = page_info[0].get_text()[-1]\n",
    "        #iterate through the rest of the results to collect data\n",
    "        for i in range(2,int(num_pages)+1):\n",
    "            #create soup for current page\n",
    "            url = rt_search_url+f\"&sort=&page={i}\"\n",
    "            html_page = requests.get(url)\n",
    "            html_tree = BeautifulSoup(html_page.content, 'html.parser')\n",
    "            #create containers for current page\n",
    "            reviews_container = html_tree.find('div', class_=\"content\")\n",
    "            review_list = reviews_container.find('div', class_='review_table') \n",
    "            #collect current page data\n",
    "            for text in texts(review_list):\n",
    "                all_text.append(text)\n",
    "            for score in scores(review_list):\n",
    "                all_scores.append(score)\n",
    "            #buffer for half a second so as to not DDOS RT\n",
    "            time.sleep(0.5)\n",
    "    #combine and return page data\n",
    "    return list(zip(all_text, all_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews for a Genre <a id='genre'></a>\n",
    "\n",
    "Lastly, we can combine these functions to get a list of reviews and their scores for movies under a specific genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_review_df(genre, num_movies):\n",
    "    \"\"\"\n",
    "    Return DataFrame with reviews and their scores collected from RT \n",
    "    using list of movies of given genre from IMDB.\n",
    "    \"\"\"\n",
    "    imdb_url = f\"https://www.imdb.com/search/title/?title_type=feature&genres={genre}&explore=genres\"\n",
    "    movie_data = collect_imdb_data(imdb_url, num_movies)\n",
    "    all_reviews = []\n",
    "#     count = 0 #debug\n",
    "    for movie in movie_data:\n",
    "#         print(f\"Currently collecting {movie} reviews.\") #debug\n",
    "        name = movie[0].lower().replace(\" \",\"_\")\n",
    "        year = movie[1]\n",
    "        for review in collect_rt_reviews(name, year):\n",
    "            all_reviews.append(review)\n",
    "#         print(f\"{name} reviews collected, {1000-count} left.\") #debug\n",
    "#         count += 1 #debug\n",
    "    return pd.DataFrame(all_reviews, columns = ['Review', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_review_df(\"horror\", 1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"../Data/reviews.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
