{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "## Table of Contents:\n",
    "1. [List of Movies](#names)\n",
    "2. [List of Reviews](#reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Movies <a id='names'></a>\n",
    "\n",
    "First, we'll need to grab our list of movie names from IMDB. We use the \"Horror\" genre because I think the words mentioned in these reviews should prove useful features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titles(movies_container):\n",
    "    \"\"\"Returns list of movie titles from IMDB search results.\"\"\"\n",
    "    return [h3.find('a').get_text() for h3 in movies_container.findAll('h3')]\n",
    "\n",
    "def years(movies_container):\n",
    "    \"\"\"Returns list of movie release years from IMDB search results.\"\"\"\n",
    "    return [h3.find('span', class_='lister-item-year text-muted unbold').get_text().strip('(I) ') for h3 in movies_container.findAll('h3')]\n",
    "\n",
    "def collect_imdb_data(imdb_seach_url, total_results):\n",
    "    \"\"\"Returns list of titles and year of release for given number of results.\n",
    "    Expect this function to take (total_results/50)/2 seconds.\n",
    "    Total results should be less than 10,000.\"\"\"\n",
    "    #initialize all lists\n",
    "    all_titles = []\n",
    "    all_years = []\n",
    "    #create soup for first page\n",
    "    html_page = requests.get(imdb_seach_url)\n",
    "    html_tree = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    #create containers for first page\n",
    "    movies_container = html_tree.find('div', class_=\"lister-list\")\n",
    "    imdb_movie_list = movies_container.findAll('div', class_=\"lister-item-content\")\n",
    "    #collect first page data\n",
    "    for title in titles(movies_container):\n",
    "        all_titles.append(title)\n",
    "    #check if total_results is greater than 10,000 since the IMDB URL changes after that many results\n",
    "    if total_results > 10_000:\n",
    "        print(\"The amount of results is too large, this function can only support up to 10,000. Collecting data for top 10,000 results only.\")\n",
    "        total_results = 10_001\n",
    "    #iterate through the rest of the results to collect data\n",
    "    for i in range(51,total_results+50,50):\n",
    "        #create soup for current page\n",
    "        url = imdb_seach_url+\"&start={i}&ref_=adv_nxt\"\n",
    "        html_page = requests.get(url)\n",
    "        html_tree = BeautifulSoup(html_page.content, 'html.parser')\n",
    "        #create containers for current page\n",
    "        movies_container = html_tree.find('div', class_=\"lister-list\")\n",
    "        imdb_movie_list = movies_container.findAll('div', class_=\"lister-item-content\")\n",
    "        #collect current page data\n",
    "        for title in titles(movies_container):\n",
    "            all_titles.append(title)\n",
    "        for year in years(movies_container):\n",
    "            all_years.append(year)\n",
    "        #buffer for half a second so as to not DDOS IMDB\n",
    "        time.sleep(0.5)\n",
    "    #combine and return page data\n",
    "    return list(zip(all_titles, all_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre = \"horror\"\n",
    "# url = f\"https://www.imdb.com/search/title/?title_type=feature&genres={genre}&explore=genres\"\n",
    "# movie_data = collect_imdb_data(url, 1_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Reviews <a id='reviews'></a>\n",
    "\n",
    "Now that we have a list of 1,000 movies and their respective release year, we can use this information to grab all of the reviews for these horror movies from Rotten Tomatoes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts(review_list):\n",
    "    \"\"\"Returns list of reviews from Rotten Tomato search results.\"\"\"\n",
    "    return [review.find('div', class_='the_review').get_text() for review in review_list.findAll('div', class_='row review_table_row')]\n",
    "\n",
    "def scores(review_list):\n",
    "    \"\"\"Returns list of scores from Rotten Tomato search results.\"\"\"\n",
    "    return [review.find('div', class_='col-xs-16 review_container').findChildren('div')[0].get('class')[-1] for review in review_list.findAll('div', class_='row review_table_row')]\n",
    "\n",
    "def collect_rt_reviews(rt_search_url):\n",
    "    \"\"\"Returns list of text and scores of reviews for given RT search results.\"\"\"\n",
    "    #initialize all lists\n",
    "    all_text = []\n",
    "    all_scores = []\n",
    "    #create soup for first page\n",
    "    html_page = requests.get(rt_search_url)\n",
    "    html_tree = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    reviews_container = html_tree.find('div', class_=\"content\")\n",
    "    review_list = reviews_container.find('div', class_='review_table')\n",
    "    for text in texts(review_list):\n",
    "        all_text.append(text)\n",
    "    for score in scores(review_list):\n",
    "        all_scores.append(score)\n",
    "    #grab number of pages\n",
    "    num_pages = reviews_container.findAll('span', class_='pageInfo')[0].get_text()[-1]\n",
    "    #iterate through the rest of the results to collect data\n",
    "    for i in range(2,int(num_pages)+1):\n",
    "        #create soup for current page\n",
    "        url = rt_search_url+f\"&sort=&page={i}\"\n",
    "        html_page = requests.get(url)\n",
    "        html_tree = BeautifulSoup(html_page.content, 'html.parser')\n",
    "        #create containers for current page\n",
    "        reviews_container = html_tree.find('div', class_=\"content\")\n",
    "        review_list = reviews_container.find('div', class_='review_table') \n",
    "        #collect current page data\n",
    "        for text in texts(review_list):\n",
    "            all_text.append(text)\n",
    "        for score in scores(review_list):\n",
    "            all_scores.append(score)\n",
    "        #buffer for half a second so as to not DDOS RT\n",
    "        time.sleep(0.5)\n",
    "    #combine and return page data\n",
    "    return list(zip(all_text, all_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm = movie_data[0][0].lower().replace(\" \",\"_\")\n",
    "# yr = movie_data[0][1]\n",
    "# url = f\"https://www.rottentomatoes.com/m/{nm}_{yr}/reviews?type=top_critics\"\n",
    "# review_data = collect_rt_reviews(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews for a Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
